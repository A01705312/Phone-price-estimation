# -*- coding: utf-8 -*-
"""Phone Price Range Estimation Hand In A01705312

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h9yRgVgU8zDNu4kdQJSjcueGo5LSv84x

# Mobile Price Clasification

#Setup

**Libraries**
"""

#Adding all the libraries at my disposal.
import pandas as pd 
import numpy as np  #For mathematical calculatons
import seaborn as sns #For data visualization
import matplotlib.pyplot as plt # For plotting graphs
import plotly.graph_objs as go
import warnings      #To ignore warnings
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
import graphviz
from sklearn.metrics import accuracy_score
from sklearn import preprocessing
from sklearn import utils
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn.tree import DecisionTreeRegressor
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import DBSCAN
from sklearn.metrics import adjusted_rand_score
from sklearn.metrics import silhouette_score
warnings.filterwarnings ("ignore")
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn import datasets
import pandas as pd
from sklearn import datasets 
from sklearn import linear_model
from sklearn.metrics import mean_squared_error, r2_score

"""**Making the connection between jupyter and Google Drive**"""

#Conecting to GDrive
from google.colab import drive

drive.mount("/content/gdrive")  
!pwd

"""**Indicating the folder in which all the files are.**



"""

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/gdrive/MyDrive/Intelligent Systems/Hand In/Jorge Hand In"
!ls

"""# Understanding the Data

Uploading and analyzing the dataset
"""

df_train = pd.read_csv('/content/gdrive/MyDrive/Intelligent Systems/Hand In/Jorge Hand In/train.csv')

"""Now we call the info of the datasets"""

df_train.info()   #General information about dataset

"""Check for missing values"""

df_train.isnull().sum()

"""We establish the categories of our data """

numerical_attribs = ["battery_power", "clock_speed", "fc", "int_memory", "m_dep", "mobile_wt", "n_cores", "pc", "px_height","px_width", "ram", "sc_h","sc_w", "talk_time"]
categorical_attribs = ["blue", "dual_sim", "four_g", "three_g", "touch_screen", "wifi"]
target = ["price_range"]

"""We eliminate the negative values"""

from sklearn.pipeline import Pipeline 
from sklearn.preprocessing import MinMaxScaler
from sklearn.compose import ColumnTransformer

num_pipeline = Pipeline([
    ("min_max_scaler", MinMaxScaler())
])

full_pipeline = ColumnTransformer([
    ("num", num_pipeline, numerical_attribs)
], remainder = "passthrough")

prepared = full_pipeline.fit_transform(df_train.drop(columns = ["price_range"], axis = 1))

"""Also physical dimensions can not be equal to 0 so we need to eliminate those rows, otherwise it will be outlier data which will affect with the develop of the algorithm."""

df_train = df_train[(df_train["px_height"] != 0) & (df_train["px_width"] != 0)]  
df_train = df_train[(df_train["sc_h"] != 0) & (df_train["sc_w"] != 0)]

"""Once the data has been purged we can plot a correlation matrix in order to determine which values afford us the most info."""

cor = df_train.corr()
plt.figure(figsize = (20, 20))
sns.heatmap(cor, annot = True, cbar = True)

"""Observing the matrix we can observe that the biggest relation with the price range is the ram characteristic, and non surprisingly other values with strong correlation are those of the dimensions, the 3G with 4G and the Pixels of the front and primary camera

In order to make our dataset smaller for making predictions, and making our software more efficient we are going to choose the main caracteristics, and drop those columns we really don't have a use for. (RAM,Pixel dimentions,battery_Power,int_memory,Camera)
"""

#First we combine the pixel Dimensions and camera values
df_train["px_dimension"] = df_train["px_height"] * df_train["px_width"] 
df_train["camera"] = df_train["fc"] * df_train["pc"]

#Then we drop all the insignificant values
df_train_2 = df_train.drop(columns = ["blue", "clock_speed", "dual_sim", "fc", "four_g", "m_dep", "mobile_wt","m_dep", "mobile_wt", "n_cores","pc","px_height","px_width","sc_h","sc_w","talk_time","three_g","touch_screen","wifi"], axis = 1)

df_train_2.info()   #General information about dataset

"""Now we split our dataset """

df_x = df_train_2[["battery_power", "int_memory", "ram", "px_dimension", "camera"]]
df_y = df_train_2[["price_range"]]

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.2, random_state = 0)

"""# Decision Trees"""

clf = tree.DecisionTreeClassifier(random_state=0, max_depth=10)
clf = clf.fit(x_train, y_train)

clf = tree.DecisionTreeClassifier(random_state=0, max_depth=10)
clf = clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)
print("Score of Decision Tree: {}".format(accuracy_score(y_test, y_pred)))

dot = tree.export_graphviz(clf, out_file=None, 
                           feature_names=["battery_power", "int_memory", "ram", "px_dimension", "camera"][:],
                           class_names=None,
                           filled=True, rounded=True,  
                           special_characters=True) 
graph = graphviz.Source(dot) 
graph

#Initialize
print("This program helps you decide if your phone is top notch or if it is so cheap it makes smoke signaling an option")
print("Please enter the characteristics of your phone")
BatteryPower = float(input("Battery Power in mAh (500-1999): "))
InternalMemory = float(input("The memory of your phone in Gb (0-64):"))
Ram = float(input("Random Access Memory capacity Mb (263-3989): "))
Px= int(input("Number of total pixels (501-3,810,186): "))
CameraPixels = int(input("Camera Pixels front*principal (0-380)"))

numpy_array = np.array([[BatteryPower, InternalMemory, Ram, Px, CameraPixels]])
new_df = pd.DataFrame(numpy_array, columns=['BatteryPower','InternalMemory','Ram','Px', 'CameraPixels'])

prediction = clf.predict(new_df)
print("\n Your phone is in the following category ", prediction)
if(prediction[0]==0):
  print("\nYou may want to start saving for a new phone")
if(prediction[0]==1):
  print("\nNot bad, just dont update the software")
if(prediction[0]==2):
  print("\nNice phone bro")
if(prediction[0]==3):
  print("\nMr Richie Rich, Hats off to you... can I see it?")

"""# Clustering"""

df_Kmean = df_train.drop(columns = ["blue", "clock_speed", "dual_sim", "fc", "four_g", "m_dep", "mobile_wt","m_dep", "mobile_wt", "n_cores","pc","px_height","px_width","sc_h","sc_w","talk_time","three_g","touch_screen","wifi","price_range"], axis = 1)
df_Kmean.head()

pca = PCA(n_components=5)
pca.fit(df_Kmean)
df2_Kmean = pca.transform(df_Kmean)

df2_Kmean = pd.DataFrame(df2_Kmean)
df2_Kmean.index = df_Kmean.index
df2_Kmean.columns = ['PCA1','PCA2','PCA3','PCA4','PCA5']
df2_Kmean.head()

#Scale Data
scaler = StandardScaler()
scaled_features = scaler.fit_transform(df2_Kmean)
df_x_Kmean= df_train_2[["battery_power", "int_memory", "ram", "px_dimension", "camera"]]
df_y_Kmean = df_train_2[["price_range"]]

df2_Kmean.plot(
        kind='scatter',
        x='PCA2',y='PCA3',
        figsize=(8,8))
plt.show()

kmeans = KMeans(n_clusters=4)
clusters = kmeans.fit(df2_Kmean)
df_Kmean['cluster'] = pd.Series(clusters.labels_, index=df_Kmean.index)
kmeans = KMeans(
    n_clusters = 4,
    init="k-means++",
    n_init=10,
    max_iter=500,
    random_state=42 )
NewCluster_ = prediction
kmeans.fit(df2_Kmean)
df_t_Kmean = scaled_features.T
plt.scatter(df_t_Kmean[0], df_t_Kmean[1], c=kmeans.labels_)
plt.show()

kmeans.inertia_

# Find the locations of the centroids
kmeans.cluster_centers_

# Find the number of iterations required to converge
kmeans.n_iter_

#A score close to 0.0 indicates random assignments, and a score close to 1 indicates perfectly labeled clusters.
#ari_kmeans = adjusted_rand_score(true_labels, kmeans.labels_)
#ari_dbscan = adjusted_rand_score(true_labels, dbscan.labels_)

NewCluster = kmeans.labels_[3]

print("\nYou are in group: ", NewCluster_)
if(NewCluster_ == 0):
  print("\That phone is not going to stop working anyday now")
if(NewCluster_ == 1):
  print("\nGo on buy a new phone, you know you deserve it")
if(NewCluster_ == 2):
  print("\nI dont know what to say, cool phone")
if(NewCluster_ == 3):
  print("\nYou like keeping on with technology, again may I see it?")

"""# Linear Regression

We are going to make a linear regression, from the previous data analysis, we can observe that the strongest correlation with the price range is the RAM characteristic so we are going to use only these values.
"""

df_train.plot('ram', 'price_range', kind ='scatter')

X = df_train[["ram"]] 
y = df_train[["price_range"]] 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)

"""Observing the previous graph we can start predicting how our linear regression is going to look, however we must continue with our procedure.
After the previous step we can start creating the linear regression object and training it using the following function.
"""

regr = linear_model.LinearRegression()
regr.fit(X_train, y_train)

"""After this we can start making predictions so those can be compared with the test previoulsy generated, and obtain the coefficient of determination, the closest this one is to 1 the better."""

# Commented out IPython magic to ensure Python compatibility.
y_pred = regr.predict(X_test)

print('Coefficient of determination: %.2f'
# % r2_score(y_test, y_pred))

"""We can observe that our coefficient of determination is 0.84 which is pretty good, all things considered that we are only using 1 variable
Finally we plot our obtained values so we can observe our lineal regression.
"""

plt.scatter(X_test, y_test,  color='red')
plt.plot(X_test, y_pred, color='green', linewidth=2)

plt.show()

"""Now we can make predictions"""

RAM1 = input("\nType the RAM characteristic: ")
    features = np.expand_dims(np.array([RAM1], dtype = 'float64'), axis=0)
    
    # Perform prediction
    new_prediction = regr.predict(features)
    print("\nThe price range of your phone is:", new_prediction)